{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader\n",
    "from instagram_dataset_v2 import InstagramDataset\n",
    "from combine_model import CombinedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "writer = SummaryWriter(log_dir='./runs/instagram_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InstagramDataset(csv_file='instagram_data.csv', root_dir='.', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuwei/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/xuwei/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = CombinedModel(num_numerical_features=3)  # 3 numerical features: no_of_comments, t, follower_count_at_t\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 448259604551744.6875, Validation Loss: 151939576746.6667\n",
      "Epoch [2/10], Train Loss: 19019042586624.0000, Validation Loss: 115656219648.0000\n",
      "Epoch [3/10], Train Loss: 5100802257197.8105, Validation Loss: 50026240021.3333\n",
      "Epoch [4/10], Train Loss: 2583874742897.1787, Validation Loss: 49605912650.6667\n",
      "Epoch [5/10], Train Loss: 1494892178507.4526, Validation Loss: 51443123498.6667\n",
      "Epoch [6/10], Train Loss: 1050801079220.5474, Validation Loss: 48408200128.0000\n",
      "Epoch [7/10], Train Loss: 707810094478.8210, Validation Loss: 44761401568.0000\n",
      "Epoch [8/10], Train Loss: 475719865613.4737, Validation Loss: 44916511392.0000\n",
      "Epoch [9/10], Train Loss: 401173977885.6421, Validation Loss: 47196576938.6667\n",
      "Epoch [10/10], Train Loss: 318881232400.1684, Validation Loss: 52003659381.3333\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, numerical_features, likes in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(images, numerical_features)\n",
    "        loss = criterion(predictions.squeeze(), likes)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Average training loss for the epoch\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, numerical_features, likes in val_loader:\n",
    "            predictions = model(images, numerical_features)\n",
    "            loss = criterion(predictions.squeeze(), likes)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    # Average validation loss for the epoch\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    # Log losses to TensorBoard\n",
    "    writer.add_scalars('Loss', {'Train': train_loss, 'Validation': val_loss}, epoch)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Close TensorBoard writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation MSE: 50727718508.3691\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_predictions, val_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, numerical_features, likes in val_loader:\n",
    "        predictions = model(images, numerical_features)\n",
    "        val_predictions.extend(predictions.squeeze().tolist())\n",
    "        val_targets.extend(likes.tolist())\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(val_targets, val_predictions)\n",
    "print(f\"Final Validation MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.19%\n",
      "Average Relative Difference on Test Set: 8.2962%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for images, numerical_features, labels in val_loader:\n",
    "        # Forward pass through the model\n",
    "        outputs = model(images, numerical_features).squeeze()\n",
    "\n",
    "        # Take logarithm of predictions and labels\n",
    "        log_preds = torch.log(outputs)\n",
    "        log_labels = torch.log(labels)\n",
    "\n",
    "        # Calculate bounds for predictions to be within 20% of true value in log space\n",
    "        lower_bound = log_labels * 0.8\n",
    "        upper_bound = log_labels * 1.2\n",
    "\n",
    "        # Check how many predictions fall within range\n",
    "        within_range = (log_preds >= lower_bound) & (log_preds <= upper_bound)\n",
    "        correct += within_range.sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / total * 100\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Calculate Average Relative Difference\n",
    "test_relative_differences = []\n",
    "with torch.no_grad():\n",
    "    for images, numerical_features, labels in val_loader:\n",
    "        # Forward pass through the model\n",
    "        outputs = model(images, numerical_features).squeeze()\n",
    "\n",
    "        # Take logarithm of predictions and labels\n",
    "        log_preds = torch.log(outputs)\n",
    "        log_labels = torch.log(labels)\n",
    "\n",
    "        # Calculate relative differences\n",
    "        relative_difference = torch.abs(log_preds - log_labels) / torch.abs(log_labels)\n",
    "        test_relative_differences.append(relative_difference)\n",
    "\n",
    "# Compute the mean relative difference\n",
    "average_relative_difference = torch.cat(test_relative_differences).mean().item()\n",
    "print(f'Average Relative Difference on Test Set: {average_relative_difference*100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 37.38%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for images, numerical_features, labels in val_loader:\n",
    "        # Forward pass through the model\n",
    "        outputs = model(images, numerical_features).squeeze()\n",
    "\n",
    "        # Take logarithm of predictions and labels\n",
    "        log_preds = outputs\n",
    "        log_labels = labels\n",
    "\n",
    "        # Calculate bounds for predictions to be within 20% of true value in log space\n",
    "        lower_bound = log_labels * 0.5\n",
    "        upper_bound = log_labels * 1.5\n",
    "\n",
    "        # Check how many predictions fall within range\n",
    "        within_range = (log_preds >= lower_bound) & (log_preds <= upper_bound)\n",
    "        correct += within_range.sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / total * 100\n",
    "    print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.43%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for images, numerical_features, labels in val_loader:\n",
    "        # Forward pass through the model\n",
    "        outputs = model(images, numerical_features).squeeze()\n",
    "\n",
    "        # Take logarithm of predictions and labels\n",
    "        log_preds = torch.log(outputs)\n",
    "        log_labels = torch.log(labels)\n",
    "\n",
    "        # Calculate bounds for predictions to be within 20% of true value in log space\n",
    "        lower_bound = log_labels * 0.9\n",
    "        upper_bound = log_labels * 1.1\n",
    "\n",
    "        # Check how many predictions fall within range\n",
    "        within_range = (log_preds >= lower_bound) & (log_preds <= upper_bound)\n",
    "        correct += within_range.sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / total * 100\n",
    "    print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
